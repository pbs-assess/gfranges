---
title: "Bolker code notes"
output: html_notebook
---


```{r setup}

```

```{r}

curve(2 * x/(1 + x), from = 0, to = 8, ylim = c(0, 10))

micmen <- function(x, a = 2, b = 1) { 
  a * x/(b + x)
}

curve(micmen(x))
```


```{r}
curve(micmen(x), from = 0, to = 8, ylim = c(0, 10))
curve(micmen(x, b = 3), add = TRUE, col = 2)
curve(micmen(x, a = 8), add = TRUE, col = 3)
abline(h = 8)
```


```{r}
xvec <- seq(0, 10, by = 0.1)

yvec=micmen(xvec) 

#OR WITH SAPPLY

sapply (yvec=sapply(xvec,micmen)) 

#OR WITH FOR LOOP

yvec <- NA
for (i in 1:length(xvec)) { 
    yvec[i]=micmen(xvec[i])
  }

plot(xvec, yvec)
lines(xvec, yvec, add = TRUE)
```

# Chapter 5: Simulations



```{r}
x = 1:20 # x varies systematically

a=2 
b=1

# Calculate the deterministic part of the model
y_det = a + b * x

# Pick 20 random normal deviates with the mean equal to the deter- ministic equation and σ = 2
y = rnorm(20, mean = y_det, sd = 2)

#OR

y = y_det+rnorm(20,sd=2) # BUT only works for normal distributions

```



```{r}
x = runif(50, min = 0, max = 5) # simulating samples from a gradient in the predictor variable

a = 20 
b=1 
k=5

y_det = a * b/(b + x)

y = rnbinom(50, mu = y_det, size = k)

plot(x, y)
curve(a*b/(b+x), add =TRUE)


```




```{r}
g = factor(rep(1:2, each = 25))

a = c(20, 10)
b = c(1, 2) 
k=5

y_det = a[g]/(b[g] + x)

y = rnbinom(50, mu = y_det, size = k)

plot(x, y, col = g)
curve(a[1]/(b[1] + x), add=TRUE)
curve(a[2]/(b[2] + x), col='red', add=TRUE)
```


```{r}
N = 603
a = 0.696
b = 9.79
mu = 25.32
zprob = 0.123
k = 0.932
# Define a function for the recruitment probability:
recrprob <- function(S) { 
      a/(1 + (a/b) * S) 
  }
#Now simulate the number of settlers and the number of recruits, using rzinbinom from the emdbook package:
library(emdbook)
?rzinbinom
S = rzinbinom(N, mu = mu, size = k, zprob = zprob)
recr = rbinom(N, prob = recrprob(S), size = S)

plot(S, recr, xlim = c(0, 200), ylim = c(0, 20))
#curve(recrprob(S), add = TRUE) 
```

```{r}

set.seed(1001)
L = 30
dispdist = 2

nparents = 50
offspr_per_parent = 10
noffspr = nparents * offspr_per_parent

# If you wanted to allow different numbers of offspring for each parent — for example, drawn from a Poisson distribution — you could use offspr_per_parent=rpois(nparents,lambda) and then rep(..., times=offspr_per_parent). Instead of specifying that each parent’s coordinates should be repeated the same number of times, you would be telling R to repeat each parent’s coordinates according to its number of offspring.
# offspr_per_parent = rpois(nparents,lambda)
# rep(..., times=offspr_per_parent)

# Pick locations for the parents:
parent_x = runif(nparents, min = 0, max = L)
parent_y = runif(nparents, min = 0, max = L)

# Pick angles and distances for dispersal:
angle = runif(noffspr, min = 0, max = 2 * pi)
dist = rexp(noffspr, 1/dispdist)

# Add the offspring displacements to the parent coordinates (using rep(...,each=offspr_per_parent)):
offspr_x = rep(parent_x, each = offspr_per_parent) +
   cos(angle) * dist
offspr_y = rep(parent_y, each = offspr_per_parent) +
   sin(angle) * dist
```


Next we calculate the neighborhood density, or the number of individuals within 2 m of each plant (not counting itself). Figure 5.4(b) shows this distribution, along with a fitted negative binomial distribution. This calculation reduces the spatial pattern to a simpler non-spatial distribution of crowding.
```{r}
pos <- cbind(offspr_x, offspr_y)
ndist <- as.matrix(dist(pos, upper = TRUE, diag = TRUE))
nbrcrowd = apply(ndist < 2, 1, sum) - 1

hist(nbrcrowd, breaks=30)
```

Next we use a relationship that Pacala and Silander found between end-of-year mass (M) and competition index (C). 
  
They fitted this relationship based on a competition index estimated as a function of the neighborhood density of conspecific (pigweed) and heterospecific (velvetleaf) competitors, C = 1 + cppnp + cvpnv. For this example, I simply made up a proportionality constant to match the observed range of competition indices. Pacala and Silander found that biomass M ∼ Gamma(shape = m/(1 + C), scale = α), with m = 2.3 and α = 0.49.

```{r}
ci = nbrcrowd * 3
M = 2.3
alpha = 0.49
mass_det = M/(1 + ci)
mass = rgamma(length(mass_det), scale = mass_det, shape = alpha)

plot(ci, log(mass))

```

Finally, we simulate seed set as a function of biomass, again using a relationship estimated by Pacala and Silander. 
Seed set is proportional to mass, with negative binomial errors: S ∼ NegBin(μ = bM,k), with b = 271.6, k = 0.569.

```{r}
b = 271.6
k = 0.569
seed_det = b * mass
seed = rnbinom(length(seed_det), mu = seed_det, size = k)

plot(log(mass),log(1+seed))
```


## Power analysis

```{r}
N = 20
x = runif(20, min = 0, max = 5)
a = 2 
b = 1
sd = 2

y_det = a + b * x

y = rnorm(N, mean = y_det, sd = sd)

m = lm(y ~ x)

coef(summary(m))["x", "Pr(>|t|)"]

nsim = 400
pval = numeric(nsim)

for (i in 1:nsim) {
    y_det = a + b * x
    y = rnorm(N, mean = y_det, sd = sd)
m = lm(y ~ x)
pval[i] = coef(summary(m))["x", "Pr(>|t|)"] 
}

sum(pval < 0.05)/nsim
```

```{r}
bvec = seq(-2, 2, by = 0.1)
power.b = numeric(length(bvec))
for (j in 1:length(bvec)) {
    b= bvec[j]
    for (i in 1:nsim) {
            y_det = a + b * x
            y = rnorm(N, mean = y_det, sd = sd)
            m = lm(y ~ x)
            pval[i] = coef(summary(m))["x", "Pr(>|t|)"]
    }
    power.b[j] = sum(pval < 0.05)/nsim
}

plot(bvec, power.b)
```

I modified code to simulate change with sample size
```{r}
a = 2 
b = 1
sd = 2

Nvec = seq(10, 50, by = 5)
power.N = numeric(length(Nvec))
for (j in 1:length(Nvec)) {
    N= Nvec[j]
    for (i in 1:nsim) {
            x = runif(N, min = 0, max = 5)      
            y_det = a + b * x
            y = rnorm(N, mean = y_det, sd = sd)
            m = lm(y ~ x)
            pval[i] = coef(summary(m))["x", "Pr(>|t|)"]
    }
    power.N[j] = sum(pval < 0.05)/nsim
}

plot(Nvec, power.N)
```

# Chapter 6: Likelihood and all that
## 6.2 PARAMETER ESTIMATION: SINGLE DISTRIBUTIONS
### 6.2.1 Maximum likelihood
#### R code for a binomial negative log-likelihood function:

```{r}
binomNLL1 = function(p, k, N) {
    -sum(dbinom(k, prob = p, size = N, log = TRUE)) 
}
```

The dbinom function calculates the binomial likelihood for a specified data set (vector of number of successes) k, probability p, and number of trials N; the log=TRUE option gives the log-probability instead of the probability (more accurately than taking the log of the product of the probabilities); -sum adds the log-likelihoods and changes the sign to get an overall negative log-likelihood for the data set.
Load the data and extract the subset we plan to work with:

```{r}
data(ReedfrogPred)
x = subset(ReedfrogPred, pred == "pred" & density ==
    10 & size == "small")
k = x$surv
x
```


We can use the optim function to numerically optimize (by default, minimizing rather than maximizing) this function. You need to give optim the objective function — the function you want to minimize (binomNLL1 in this case) — and a vector of starting parameters. You can also give it other information, such as a data set, to be passed on to the objective function. The starting parameters don’t have to be very accurate (if we had accurate estimates already we wouldn’t need optim), but they do have to be reasonable. That’s why we spent so much time in Chapters 3 and 4 on eyeballing curves and the method of moments.

```{r}
O1 = optim(fn = binomNLL1, par = c(p = 0.5), N = 10,
    k = k, method = "BFGS")

O1$par
exp(-O1$value)
```

optim insists that you specify all of the parameters packed into a single numeric vector in your negative log-likelihood function. mle prefers the parameters as a list. mle2 will accept either

mle2 assumes that the objective function is a negative log-likelihood function. The names of the arguments are easier to understand: minuslogl instead of fn for the negative log-likelihood function, start instead of par for the starting parameters, and data for additional parameters and data.

```{r}
library(bbmle)
m1 = mle2(minuslogl = binomNLL1, start = list(p = 0.5),
    data = list(N = 10, k = k))
m1

m2 = mle2(k ~ dbinom(prob = p, size = 10), start = list(p = 0.5), data = list(k = x$surv))
m2
```

## Gamma
#### 6.2.1.2 Myxomatosis data: Gamma likelihood

```{r}
data(MyxoTiter_sum)
myxdat = subset(MyxoTiter_sum, grade == 1)

gammaNLL1 = function(shape, scale) {
    -sum(dgamma(myxdat$titer, shape = shape, scale = scale, log = TRUE))
}

```


find starting parameters for the Gamma distribution: 
use the method of moments (Chapter 4) to determine reasonable starTing values for the scale (=variance/mean=coefficient of variation [CV]) and shape(=variance/mean2=mean/CV) parameters
```{r}
gm = mean(myxdat$titer)
cv = var(myxdat$titer)/mean(myxdat$titer)
```


fit the data:
```{r}
m3 = mle2(gammaNLL1, start = list(shape = gm/cv,
   scale = cv))
m3
```

```{r}
m3 = mle2(myxdat$titer ~ dgamma(shape, scale = scale),
          start = list(shape = gm/cv, scale = cv), 
          data = list(myxdat$titer))
m3
```

```{r}
f1 = MASS::fitdistr(myxdat$titer, "gamma")
f1
```

#### 6.2.2.2 Gamma distribution: multiparameter distributions and non-conjugate priors

```{r}
prior.as = function(a, s) {
  dgamma(a, shape = 0.01, scale = 100) * dgamma(s, shape = 0.1, scale = 10)
}

unscaled.posterior = function(a, s) {
  prior.as(a, s) * exp(-gammaNLL1(shape = a, scale = s)) 
}
```

## 6.3 MORE COMPLEX FUNCTIONS
### 6.3.1 Maximum likelihood
#### 6.3.1.1 Tadpole predation
Since the distribution and density functions in R (such as dbinom) operate on vectors just as do the random-deviate functions (such as rbinom) used in Chapter 5, I can translate this model definition directly into R, using a numeric vector p={a, s} for the parameters:
```{r}
binomNLL2 = function(p, N, k) {
    a = p[1]
    h = p[2]
    predprob = a/(1 + a * h * N)
    -sum(dbinom(k, prob = predprob, size = N, log = TRUE))
}
```


eyeballing the initial slope and asymptote gives us crude starting estimates of a (initial slope) at around 0.5 and h (1/asymptote) at around 1/80 = 0.0125

```{r}
data(ReedfrogFuncresp)
attach(ReedfrogFuncresp)
O2 = optim(fn = binomNLL2, par = c(a = 0.5, h = 0.0125),
    N = Initial, k = Killed)
```


mle2 for this purpose, you would normally have to rewrite the negative log-likelihood function with the parameters a and h as separate arguments (i.e. function(a,h,p,N,k)). However, mle2 will let you pass the parameters inside a vector as long as you use parnames to attach the names of the parameters to the function.
```{r}
parnames(binomNLL2) = c("a", "h")
m2 = mle2(binomNLL2, start = c(a = 0.5, h = 0.0125),
   data = list(N = Initial, k = Killed))
m2
```

#### 6.3.1.2 Myxomatosis virus
```{r}
gammaNLL2 = function(a, b, shape) {
  meantiter = a * myxdat$day * exp(-b * myxdat$day)
  -sum(dgamma(myxdat$titer, shape = shape, scale = meantiter/shape, log = TRUE))
}
```

```{r}
m4 = mle2(gammaNLL2, start = list(a = 1, b = 0.2,
     shape = 50), method = "Nelder-Mead")
m4
```

```{r}
mle2(titer ~ dgamma(shape, scale = a * day * exp(-b *
     day)/shape), start = list(a = 1, b = 0.2, shape = 50),
     data = myxdat, method = "Nelder-Mead")

```

### 6.4.1.1 The Likelihood Ratio Test

R can compute profiles and profile confidence limits automatically. 

Given an mle2 fit m, profile(m) will compute a likelihood profile and confint(m) will compute profile confidence limits. plot(profile(m2)) will plot the profile, square-root transformed so that a quadratic profile will appear V-shaped (or linear if you specify absVal=FALSE). This transforma- tion makes it easier to see whether the profile is quadratic, since it’s easier to see whether a line is straight than it is to see whether it’s quadratic. Computing the profile can be slow, so if you want to plot the profile and find confidence limits, or find several different confidence limits, you can save the profile and then use confint on the profile:

```{r}
profile(m2)
confint(m2)
plot(profile(m2), absVal=FALSE)
p2 = profile(m2)
confint(p2)
```

```{r}
binomNLL2.a = function(p, N, k, a) {
  h = p[1]
 p = a/(1 + a * h * N)
 -sum(dbinom(k, prob = p, size = N, log = TRUE))
}
  
```

```{r}
avec = seq(0.3, 0.8, length = 100)
aprof = numeric(100)
for (i in 1:100) {
  aprof[i] = optim(binomNLL2.a, par = 0.02, k = ReedfrogFuncresp$Killed,
    N = ReedfrogFuncresp$Initial, a = avec[i],
    method = "BFGS")$value
}

plot(avec,aprof)
```

```{r}
prof.lower = aprof[1:which.min(aprof)]
prof.avec = avec[1:which.min(aprof)]

approx(prof.lower, prof.avec, xout = -logLik(m2) +
     qchisq(0.95, 1)/2)
```

